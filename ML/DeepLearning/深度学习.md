# 深度学习

神经网络大智由输入层，隐藏层，输出层组成

层与层之间的神经元有连接，而层内之间的神经元没有连接。连接的神经元都有对应的权重

最左边的层叫做输入层，这层负责接收输入数据

最右边的层叫输出层，我们可以从这层获取神经网络输出数据

输出层和输入层之间的层叫隐藏层

隐藏层比较多（大于2）的神经网络叫做深度神经网络。而深度学习就是深层架构的机器学习方法

深度学习本质上和机器学习还是很相似的，都通过去训练一个模型，然后将输入的数据通过模型映射到一个预测值

在训练的时候，通过比较预测值和真实值的误差通过一个损失函数得到的损失值，然后根据损失值来调整隐藏层里的权重，最后我们会得到比较合适的各种权重值

# 前馈网络和感知机

深度学习都是从感知机发展过来

上个世纪六十年代，提出了最早的“人造神经元”模型，叫做“感知机”，直到今天还在用。感知机是最早被设计并被实现的人工神经网络。是一种非常特殊的神经网络,它在人工神经网络的发展史上有着非常重要的地位。

感知机是一个二分类**线性**分类模型，输入为实例的特征向量，输出为实例的类别
$$
f(x) = sign(wx+b)\\
sign(x)=\left\{  
             \begin{array}{**lr**}  
             +1,wx+b\ge0  \\  
             -1,wx+b\le0\\ 
             \end{array}  
\right.
$$
wx+b 权重 w 反应了对应输入的重要性，权重值的绝对值越大说明这个因素越重要，偏置 b 反映了意愿强烈程度，越大表示越想去，越小表示越不想去，sign 函数则起到一个分类的作用

## 感知机算法

训练数据集
$$
T={(x_1,y_1),(x_2,y_2),...,(x_n,y_n)},\\其中x_i\in R^n;y_i\in {+1,-1}, i=1,2...n;学习率\eta(0<\eta<1)
$$

1. 选取初始值$w_0,b_0$
2. 在训练数据中选取数据$(x_i,y_i)$
3. 如果 $y_i(w.x_i+b)\le 0$

$$
w:=w-\eta\frac{\partial l(w,b)}{\partial w}=w+\eta y_i x_i\\
b:=b-\eta\frac{\partial l(w,b)}{\partial b}=b+\eta y_i
$$

## 深度前馈网络

也叫前馈神经网络或者多层感知机，是典型的深度学习模型

前馈网络的目标是去拟合某个函数

这种模型是向前的，是因为我们的输入 X，通过某个函数 f 的中间计算过程，最终到达输出 y。在模型的输出和模型本身之间没有反馈连接

当前馈神经网络被拓展成包含反馈连接时，它们被称为 bp 神经网络即反向传播神经网络

前馈神经网络被称作网络是因为它们通常用许多不同函数复合在一起来表示。例如，我们有 n 个函数 $f^{(1)},f^{(2)}...f^{(n)}$ 连接在一个链上以形成 $f(x)=f^{(n)}(...f^{(3)}(f^{(2)}(f^{(1)}(x))))$ 这些链式结构是神经网络中最常用的结构。在这种情况下，f(1) 被称为网络的第一层，f(2) 被称为第二层，以此类推。

链的全长称为模型的深度。也是因为这样，所以出现了深度学习这个名字。

前馈网络的最后一层被称为输出层。

我们训练神经网络的目的就是让 f(x) 去匹配 f*(x) 的值

### 激活函数

在神经元中，输入通过加权求和之后，还被作用了一个非线性函数，这个函数就是激活函数

现实生活中很多问题都是一个非线性的问题，所以我们需要这样一个**非线性**的函数对这些复杂问题作更好的映射

如果没有激活函数，不管有多少个神经元，多少层神经元，输入 X 与输出 Y 还是一个线性关系，这样就没有意义了

常用的激活函数：
**sigmoid**
$$
sigmoid(x)=\frac{1}{1+e^{-x}}\\
sigmoid'(x)=sigmoid(x)*(1-sigmoid(x))
$$
优点：

1. sigmoid 函数的输出映射在（0,1）之间，可以用来做二分类，单调连续，输出范围有限，优化稳定，可以用作输出层
2. 求导容易

缺点：

1. 梯度消失：反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练，导致训练出现问题
2. 计算成本高昂： 指数函数相比其他激活函数，计算成本高昂。
3. 不以零为中心：这个特性会导致后面网络层的输入也不是零中心的，这将会导致梯度下降权重更新时出现 z 字型的下降，进而影响梯度下降的运作

**tanh**
$$
tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}\\
tanh'(x)=1-(tanh(x))^2
$$
优点：

1. 相比 sigmoid 函数，其输出以 0 为中心，比 sigmoid 函数收敛速度快

缺点：

1. 梯度消失
2. 计算成本高昂

**Relu**
$$
Relu(x)=max(0,x)\\
Relu'(x)=\begin{equation}  
\left\{  
             \begin{array}{**lr**}
             0, & x\lt 0.\\  
             1, & x\gt 0.  
             \end{array}  
\right.  
\end{equation}
$$
优点：

1. 使用 Relu 的收敛速度会比 sigmoid/tanh 快很多
2. 提供了神经网络的稀疏表达能力（relu 函数在负半区的导数为 0，所以一旦神经元激活值进入负半区，那么梯度就会为 0，也就是说这个神经元不会经历训练，即所谓的稀疏性，与梯度消失的区别是梯度消失即弥散是指梯度很小网络训练不动，这个是直接不训练使得网络稀疏）

缺点：

1. 不以为零为中心
2. Dead Relu Problem

### 损失函数

神经网络以某个指标为线索寻找最优权重参数，神经网络的学习中，所用的指标称为损失函数

我们希望损失函数

1. 连续，可导，且导数不是处处为零
2. 非负

#### 回归常见损失函数

MSE 均方误差

均方误差是最常用的回归损失函数，它是我们额目标变量和预测的差值平方和
$$
MSE=\frac{1}{n}\sum_{i=1}^n(y_i-\hat{y_i})^2
$$
偏导求梯度
$$
\frac{\partial MSE}{\partial w_i}=2x_i(w_ix_i+b_i-y_i)=2x_i(\hat{y_i}-y_i)
$$
MAE 平均绝对误差

平均绝对误差是另一种用于回归模型的损失函数。MAE 是目标变量和预测变量之间绝对差值之和
$$
MAE=\frac{1}{n}\sum_{i=1}^n|y_i-\hat{y_i}|
$$
梯度
$$
\frac{\partial MAE}{\partial w_i}=\begin{equation}  \left\{               \begin{array}{**lr**}             -x_i, & w_ix_i+b_i-y_i\lt 0.\\               x_i, & w_ix_i+b_i-y_i\gt 0.               \end{array}  \right.  \end{equation}
$$
MSE 更容易求解，但是对抗异常值比较差

#### 分类常用损失函数

MSE 并不合适

交叉熵损失函数

一个事件发生的概率越大，则它携带的信息量就越小

熵表示不确定度，为信息量的期望

熵的单位随着公式 log 运算的底数变化，当底数为 2 时单位为比特，底数为 e 时，单位为奈特
$$
H(x)=-[p(x)logp(x)+(1-p(x))log(1-p(x))]\\
H(0.5)=1
$$

p 是真是的分布，q 是模型预测出来的分布。交叉熵是非对称的，描述的是假设一个预测的概率分布 q 服从的是真实分布 p，所需要的平均信息。

如果预测的分布 q 越接近真是的分布 p，那么这个信息量就越小。

我们所要做的就是优化交叉熵，是其值越小，从而使得模型预测的概率分布月接近真是的概率分布

### 优化

#### 梯度下降

梯度的本意是一个向量，表示某一个函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向变化最快，变化率最大
$$
\theta_j:=\theta_j-\eta\frac{\partial J(\theta_j)}{\partial\theta_j}
$$
学习率不能过大和过小

BGD：Batch Gradient Descent 取整体

优点：保证全局最优

缺点：收敛慢，不能在线新加入数据

SGB: Stochastic Gradient Descent 每次随机取一个样本进行训练

优点：收敛速度快，可以在线更新数据

缺点：大部分的时候向着全局最小值，但有时候会远离最小值，所以会受噪声影响，甚至可能一直不能收敛到最小值，一直在最小值旁边徘徊

mini-batch Gradient Descent 的方法是在上述两个方法中去取折衷

共同缺点：对 learning rate 的设置较为敏感，太小则训练的太慢，太大则容易使目标函数发散掉

针对不同的参数，learning rate 都是一样的。这对于稀疏数据来说尤为不方便，因为我们更想对那些经常出现的数据采用较小的 step size，而对于较为罕见的数据采用更大的 step size

梯度下降法的本质是寻找不动点（目标函数对参数的倒数为0的点）而这种不动点通常包括三类：极大值、极小值、鞍点。高维非凸空间中存在大量的鞍点，是的梯度下降法极易陷入鞍点（saddle points）且长时间出不来

#### 动量梯度下降

Momentum
$$
v_t=\gamma v_{t-1}+\eta \nabla_\theta J(\theta)\\
v_0=0\\
\theta=\theta-v_t
$$
加上动量顶就像从山顶滚下一个球，球往下滚的时候累积了前面的动量 （ 动量不断增加 ), 因此速度变得越来越快，直到到达终点

同理，在更新模型参数时，对于那些当前的梯度方向与上一次梯度方向相同的参数，那么进行加强，即这些方向上更快了；对于那些当前的梯度方向与上一次梯度方向不同的参数，那么进行削减，即这些方向上减慢了。因此可以获得更快的收敛速度与减少振荡

momentum 方法的优点在于可以使网络能更优和更稳定的收敛，井减少振荡过程。缺点是下坡的过程中动量越来越大，在最低点的速度太大了， 可能又冲上坡导致错过极小点 

这样一直保持着之前的梯度，在遇到鞍点的时候就不会被困。 在垂直方向，当往下或下走的时候由于保持着之前反方向的梯度，所以上下震荡的幅度不会太大。水平方向由于一直 保持着同方向的梯度所以速度会越来越快。 坏处就是这样也会导致在最优点的时候冲过最优解。 

#### NGA

Nesterov accelerated gradient （NAG，涅斯捷罗夫梯度加速）
$$
v_t=\gamma v_{t-1}+\eta \nabla_\theta J(\theta-\gamma v_{t-1})\\
\theta=\theta-v_t
$$
在小球向下滚动的过程中，我们希望小球能够提前知道在哪些地方坡面会上升，这样在遇到 上升坡面之前，小球就开始减速。防止冲上坡 

在第 t 步时，已经把 t+1 步时的梯度考虑进来了

在梯度为 $\theta$ 处，使用的梯度为 $\theta-v_t$ ，等于说在提前进行了减速，从而达到防治冲过谷底的目的

#### 自适应学习率算法

#### Adagrad

# 神经网络的传播

计算图是一种用来描述函数的语言

图中的节点代表计算（函数的输入）边代表的是数据的流向。(可以是常数,向量,张量)

看到一个计算图,我们就可以很容易的写出其对应的函数

前向传播

反向传播

反向传播其实就是利用前向传播得到的预测值,与真实值比较,得到一个损失函数L.

求出损失函数对各个参数的梯度,再利用梯度下降法,对所有的参数进行优化更新。

# 正则化

## 参数范数惩罚

参数范数惩罚方法是通过对损失函数添加一个参数范数惩罚项,限制模型的学习能力常见的方法有L1正则, L2正则

L1和L2正则化的区别

都是减小权重,方法不同:

1. L1减少一个常量, L2减少权重的一个固定比例
2. 如果权重本身很大, L1减少的比L2少很多
3. 如果权重本身很小, L1减少的更多

## Drop out

Dropout是一种相当激进的技术。和L1, L2正则化不同, Dorpout技术并不依赖对损失函数的修改。而是,在Dropout中,我们改变了网络本身.

我们用mini batch的方式每次从数据中随机取一部分拿来训练网络,相应的每次隐藏层的神经元也会随机的使一部分不工作.

工作的神经元所对应的权重和偏置就进行训练,不工作的就不训练,最后我们会学习到一堆的权重和偏置

假如说你每次使0.5的神经元不工作,你最后得到的参数就得乘以(1-0.5),假如你每次使0.2的神经元不工作你最后得到的参数就得乘以(1-0.2) ,这就是Dropout的过程(通常每次使一半的神经元不工作)

我们按照以前的方式对神经网络进行训练,假如我们同时训练5个这样的神经网络用来识别猫和狗,由于每个网络都是从不同的初始状态进行训练的,所以,最终的结果也会有一定的差异,出现这样的情况,我们可以使用一些平均或者投票的方式来确定接受哪个输出,比如,有三个神经网络判定图片为猫,两个判定为狗,那么,它就很可能是猫,其它的两个神经网络就很可能犯了错误,这种平均的方式是一种很强大的方式来减轻过拟合.因为在不同的网络可能会以不同的方式过拟合,平均的方法有机会帮我们消除这些过拟合

而我们使用Dropout的方法来训练神经网络,就好像每次在训练不同的神经网络, Dorpout的过程,就好像把大量不同的神经网络的效果进行平均不同的网络以不同的方式过拟合,而Dorpout就能够减轻过拟合

另一个原因就是,我们的神经元都在学习不同的特征, Dorpout的方法可以防止每个神经元过度的去学习某一个特征,强制去学习不同的特征,防止某个权重过大,这方面跟L1 , L2正则化有些相似

## 其他正则化方法

让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。当然,在实践中,我们拥有的数据量是很有限的,解决这个问题的一种方法是创建假数据并添加到训练集中。对于一些机器学习任务,创建新的假数据相当简单

常见方法有翻转，旋转，缩放

对于语音数据,我们可以通过在里面添加噪音来达到数据增强的目的

因为我们训练的时候的语音数据可能是在室内非常安静的时候录下来的,而在测试的时候.对室外非常嘈杂这种情况也要能有很好的识别,所以,给语音数据添加噪音,也是一种数据增强的手段

提前终止

我们在训练模型时,会发现,在训练集上,误差会随着训练次数的增多而不断降低,但是在验证集上,误差在降低到某个地方的时候,会开始上升

提前终止,指的就是,我们这个模型在迭代过程中已经训练的很好了,我们就此终止训练吧
# 朴素贝叶斯

Inside every non Bayesian there is a Bayesian struggling to get out. -- Dennis V.Lindley

- 更纯粹的概率问题
- 条件概率与贝叶斯
- 贝叶斯分类器的基本方法
- 连续型变量中的贝叶斯分类器 
- 贝叶斯需要注意的一些问题
- 相关API与超参数

## 概率计算知识

先验概率：固有知识

后验概率：更新的知识

条件概率：B 发生的情况下，A 发生的概率就是 P(A|B)
$$
P(A|B)=\frac{P(AB)}{P(B)}
$$
在下面的最简单的贝叶斯公式中
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$
**posterior 后验概率**就是 P(A|B)

**Probability of evidience 依据的概率**就是 P(B)

**Probability of prior 先验概率**就是 P(A)

**likehood 似然**就是 P(B|A)

## 贝叶斯分类器的基本方法

$$
P(类别|特征)=\frac{P(特征|类别)P(类别)}{P(特征)}
$$

$$
P(C_j|x_1,x_2...x_n)=\frac{\bigg(\prod_{i=1}^n(P(x_i|C_j)\bigg)P(C_j)}{P(x_1,x_2...x_n)}
$$

如何计算某个事件概率

根据训练数据，统计或估计贝叶斯公式中的已知量，根据贝叶斯定理计算出结果概率

统计对应离散型变量

估计可以用于离散型变量也可以用于连续型变量

### 连续型变量中的贝叶斯分类器

对于连续型变量，贝叶斯分类器假设其符合高斯分布
$$
\mu=\frac{1}{n}\sum_{i=1}^nx_i,\sigma=\bigg[\frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2\bigg]^{0.5}\\
f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}
$$
虽然高斯分布看着复杂，但是它只要两个参数

标准差 $\sigma$ 越小，$\mu$ 的地方就越高，且都会向 $\mu$ 的地方靠拢

## 贝叶斯需要注意的一些问题

使用贝叶斯的假设前提：各个变量（特征）之间相互独立

这也是贝叶斯算法的分类器被称之为“朴素贝叶斯”的原因

特点：

1. 快，非常快，只需要统计或者估算概率，然后使用公式计算
2. 理论上来说，需要的样本量并不大，而且效果很好
3. 非常适合离散型变量分析
4. 多分类和二分类处理起来完全一样

应用场景：主要是文本分类，文本情感识别，垃圾邮件分类等等

贝叶斯本身不仅仅能够应用到实际场景中去

同时也是诸多机器学习方法的基石

比如机器学习中的高级自动调参方法贝叶斯优化


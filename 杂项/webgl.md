# webgl

[例子展示网站](https://sites.google.com/site/webglbook/home)

Webgl 中最重要的要记住两个着色器，顶点着色器和片元着色器。

webgl 渲染视图主要是两步，图形装配过程和光栅化过程。

-  图形装配过程：这一步的任务是，将孤立的顶点坐标装配成几何图形。几何图形的类别由 `gl.drawArrays()` 的第一个参数决定。
- 光栅化过程：这一步的任务是，将装配好的几何图形转化为片元

被装配出的基本图形又被称为图元（primitives），一旦光栅化过程结束后，程序就开始逐片元调用片元着色器

我们吧顶点的颜色复制给了顶点着色器中的 `varying` 变量 `v_Color`，它的值被传给了片源着色器中的同名，同类型变量，顶点着色器中的 `v_Color` 变量在传入片元着色器之前经过了内插过程。顶点着色器中的 `v_Color` 变量和顶点着色器中的 `v_Color` 变量实际上并不是一回事，这也正是我们将这种变量成为 varying ( 变化的 ) 变量的原因

### 颜色内插

一个红色点和蓝色点连成的线段上。颜色由 (1.0, 0.0, 0.0) 到 (0.0, 0.0, 1.0) ，rgba 的值中 r 会从 1.0 到 0.0，b 的值会从 0.0 到 1.0，线段上的所有片元的颜色值都会被恰当地计算出来，这个过程就被成为内插过程（interpolation process）

一旦两点之间的每个片元的新颜色都通过这种方式被计算出来后，它们就会被传给片元着色器中的 `v_Color` 变量

光栅化是三维图形学的关键技术之一，它负责将矢量的几何图形转变为栅格化的片元（像素），图形被转化为片元之后，我们就可以在片元着色器内做更多的事情，如为片元指定不同的颜色。颜色可以内插出来，也可以编程指定

## 移动、旋转和缩放

### 平移

$$
x^` = x + T_x\\
y^` = y + T_y\\
z^` = z + T_z
$$

### 旋转

懒得写 $\beta$​​​ ，下面 b 和它等价

a点在 (x, y)
$$
x = r \cos{\alpha}\\
y = r \sin{\alpha}\tag{1}
$$
旋转 $\beta$​​​ 角度到 (x\`, y\`)
$$
x^` = r \cos{(\alpha + \beta)}\\
y^` = r \sin{(\alpha + \beta)}\\\tag{2}
$$
根据三角函数两角和公式
$$
\sin{(a\pm b)}=\sin{a}\cos{b}\mp\cos{a}\sin{b}\\
\cos{(a\pm b)}=\cos{a}\cos{b}\mp\sin{a}\sin{b}
$$
可得
$$
x^` = r (\cos{a}\cos{b}-\sin{a}\sin{b})\\
y^` = r (\sin{a}\cos{b}+\cos{a}\sin{b})\\
$$
再将最开始的式（1）带入，得
$$
x^`=x\cos{b}-y\sin{b}\\
y^`=x\sin{b}-y\cos{b}\\
z^`=z\tag{3}
$$
矩阵表示就是
$$
\left[
 \begin{matrix}
   x^` \\
   y^` \\
   z^`
  \end{matrix}
\right] = \left[
 \begin{matrix}
   \cos{\beta} & -\sin{\beta} & 0 \\
   \sin{\beta} & \cos{\beta} & 0 \\
   0 & 0 & 1
  \end{matrix}
\right] \times \left[
 \begin{matrix}
   x \\
   y \\
   z
  \end{matrix}
\right] \tag{4}
$$
等式（4）考虑了旋转，有平移就不够了，所以要有个 4 × 4 的矩阵
$$
\left[
 \begin{matrix}
   x^` \\
   y^` \\
   z^` \\
   1
  \end{matrix}
\right] = \left[
 \begin{matrix}
   a & b & c & d \\
   e & f & g & h \\
   i & j & k & l \\
   m & n & o & p
  \end{matrix}
\right] \times \left[
 \begin{matrix}
   x \\
   y \\
   z \\
   1
  \end{matrix}
\right] \tag{5}
$$
平移矩阵就是
$$
\left[
 \begin{matrix}
   x^` \\
   y^` \\
   z^` \\
   1
  \end{matrix}
\right] = \left[
 \begin{matrix}
   1 & 0 & 0 & T_x \\
   0 & 1 & 0 & T_y \\
   0 & 0 & 1 & T_z \\
   0 & 0 & 0 & 1
  \end{matrix}
\right] \times \left[
 \begin{matrix}
   x \\
   y \\
   z \\
   1
  \end{matrix}
\right]
$$
旋转矩阵就是
$$
\left[
 \begin{matrix}
   x^` \\
   y^` \\
   z^` \\
   1
  \end{matrix}
\right] = \left[
 \begin{matrix}
   \cos{\beta} & -\sin{\beta} & 0 & 0\\
   \sin{\beta} & \cos{\beta} & 0  & 0\\
   0 & 0 & 1 & 0 \\
   0 & 0 & 0 & 1 \\
  \end{matrix}
\right] \times \left[
 \begin{matrix}
   x \\
   y \\
   z \\
   1
  \end{matrix}
\right] \tag{4}
$$
在 webgl 和 opengl 中我们向一个 array 里传值的时候是列主序的，比如要传入式（5）中的 4 × 4 矩阵的话，顺序就是 `[a, e, i, m, b, f, j, n, c, g, k, o, d, n, l, p]`

### 复合变换

等式4.1
$$
<'平移'后的坐标>=<平移矩阵>\times<原始坐标>
$$
然后对<平移后的坐标>进行旋转。

等式4.2
$$
<'平移后旋转'后的坐标>=<旋转矩阵>\times<平移后的坐标>
$$
当然你也可以分步计算这两个等式，但更好的方法是,将等式4.1代入到等式4.2中，把两个等式组合起来:

等式4.3
$$
<'平移后旋转'后的坐标>= < 旋转矩阵>\times(<平移矩阵>\times<原始坐标>)
$$
这里
$$
<旋转矩阵>\times(<平移矩阵>\times<原始坐标>)
$$
等于(注意括号的位置)
$$
(<旋转矩阵>\times<平移矩阵>)\times<原始坐标>
$$
最后，我们可以在 JavaScript 中计算 `<旋转矩阵>x<平移矩阵>`，然后将得到的矩阵传人顶点着色器。像这样，我们就可以把多个变换复合起来了。一个模型可能经过了多次变换，将这些变换全部复合成一个等效的变换，就得到了模型变换 (model transformation)，或称建模变换 (modeling transformation)，相应地，模型变换的矩阵称为模型矩阵 (model matrix)。

矩阵相乘的次序很重要，`A*B`的结果并不一定等于 `B*A`。

## 纹理

### 激活纹理单元

WebGL通过一种称作纹理单元 ( texture unit ) 的机制来同时使用多个纹理。每个纹理单元有一个单元编号来管理一张纹理图像。即使你的程序只需要使用一张纹理图像，也得为其指定一个纹理单元。

系统支持的纹理单元个数取决于硬件和浏览器的 WebGL 实现，但是在默认情况下，WebGL 至少支持 8 个纹理单元，一些其他的系统支持的个数更多。内置的变量 `gl. TEXTRUE0`、`g1.TEXTURE1`.....`g1. TEXTURE7`各表示一个纹理单元。

在使用纹理单元之前，还需要调用 `gl.activeTexture()` 来激活它

### 绑定纹理对象 (gl.bindTexture())

接下来，你还需要告诉WebGL系统纹理对象使用的是哪种类型的纹理。在对纹理对象进行操作之前，我们需要绑定纹理对象，这一点与缓冲区很像:在对缓冲区对象进行操作(如写人数据)之前，也需要绑定缓冲区对象。WebGL 支持两种类型的纹理

- `gl. TEXTURE_2D` 二维纹理
- `gl . TEXTURE_CUBE_MАP` 立方体纹理

注意，该方法完成了两个任务:开启纹理对象，以及将纹理对象绑定到纹理单元上。在本例中，因为0号纹理单元 (`g1.TEXTURE0`) 已经被激活了

### 配置纹理对象的参数(gl.texParameteri())

- 放大方法(`g1.TEXTURE_MAG_FILTER`) :这个参数表示，当纹理的绘制范围比纹理本身更大时，如何获取纹素颜色。比如说，你将 16 x 16 的纹理图像映射到 32 x 32 像素的空间里时，纹理的尺寸就变成了原始的两倍。WebGL需要填充由于放大而造成的像素间的空隙，该参数就表示填充这些空隙的具体方法。
- 缩小方法(`g1.TEXTURE_MIN_FILTER`) : 这个参数表示，当纹理的绘制范围比纹理本身更小时，如何获取纹素颜色。比如说，你将 32 x 32 的纹理图像映射到 16 x 16 像素的空间里，纹理的尺寸就只有原始的一半。为了将纹理缩小，WebGL需要剔除纹理图像中的部分像素，该参数就表示具体的剔除像素的方法。
- 水平填充方法(`gl.TEXTURE_WRAP_S`) :这个参数表示，如何对纹理图像左侧或右侧的区域进行填充。
- 垂直填充方法(`gl.TEXTURE_WRAP_T`) :这个参数表示，如何对纹理图像上方和下方的区域进行填充。

### 将纹理图像分配给纹理对象(gl.texlmage2D())

我们使用gl.texImage2D()方法将纹理图像分配给纹理对象，同时该函数还允许你告诉WebGL系统关于该图像的一些特性。

```js
// Set the texture image
gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, image);
```

这时，Image 对象中的图像就从 JavaSeript 传人WebGL 系统中，并存储在纹理对象中

### 将纹理单元传递给片元着色器(gl.uniform1i())

一旦将纹理图象传入了WebGL系统，就必须将其传人片元着色器并映射到图形的表面上去。如前所述，我们使用 uniform 变量来表示纹理，因为纹理图像不会随着片元变化。

### 从顶点着色器向片元着色器传输纹理坐标

由于我们是通过attribute变量a_TexCoord接收顶点的纹理坐标，所以将数据赋值给 varying 变量 v_TexCoord 并将纹理坐标传人片元着色器是可行的。你应该还记得，片元着色器和顶点着色器内的同名、同类型的 varying 变量可用来在两者之间传输数据。顶点之间片元的纹理坐标会在光栅化的过程中内插出来，所以在片元着色器中，我们使用的是内插后的纹理坐标。

### 在片元着色器中获取纹理像素颜色(texture2D())

片元着色器从纹理图像上获取纹素的颜色。

## 三维

### 视点、观察目标点和上方向

为了确定观察者的状态，你需要获取两项信息：视点，即观察者的位置；观察目标点(look-at point)，即被观察目标所在的点，它可以用来确定视线。此外，因为我们最后要把观察到的景象绘制到屏幕上，还需要知道上方向(up direction)。 有了这三项信息，就可以确定观察者的状态了。

除了水平和垂直范围内的限制, WebGL还限制观察者的可视深度，即“能够看多远”。所有这些限制，包括水平视角、垂直视角和可视深度，定义了**可视空间(view volume)**。由于我们没有显式地指定可视空间，默认的可视深度又不够远，所以三角形的一个角看上去就消失了。

可视空间：

- 长方体可视空间，盒状空间，由**正射投影（orthographic projection）**产生
- 四棱锥、金字塔可视空间，由**透视投影（perspective projection）**产生

长方体可视空间由前后两个矩形表面确定，分别称近裁剪面(near clipping plane)和远裁剪面(far clipping plane)，前者的四个顶点为(right, top, -near)， (-left, top, - -near)，(-left, -bottom, - -near)，(right, -bottom, - -near)，而后者的四个顶点为(right, top, far)，(-left, top, far)，(-left, - bottom, far)，(right, -bottom, far)。

其实就是一个长方体，被z轴平行穿过，通过上下左右决定穿过的点，near和far的距离就是空间沿着z轴的长度，其实通常 near 和 far 的值互换是不会有啥变化的

透视的可视空间就是个四棱锥，可视空间的参数是垂直视角，宽高比，近远裁剪面

还要设置

```js
  // Enable depth test
  gl.enable(gl.DEPTH_TEST);
  // Clear color and depth buffer
  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
```

这才能正确显示前后深浅关系

如果有相同的 z 值

```
gl.enable(gl.POLYGON_OFFSET_FILL)
gl.polygonOffset(1.0, 1.0)
```

## 光照

在三维图形学中术语着色 (shading) 的真正含义就是，根据光照条件重建“物体各表面明暗不一的效果”的过程。物体向地面投下影子的现象，又被称为阴影(shadowing)。

物体表面反射光线的方式有两种:漫反射 (diffuse reflection) 和环境反射 (enviroment/ambientreflection) 。本节的重点是如何根据上述两种信息(人射光和物体表面特性)来计算出反射光的颜色。本节会涉及- -些简单的数学计算。

漫反射

我们将人射角定义为人射光与表面的法线形成的夹角，并用θ表示

```
<漫反射光颜色> = <入射光颜色> × <表面基底色> × cosθ
```

环境反射

```
<环境反射光颜色> = <入射光颜色> × <表面基底色>
这里的<入射光颜色>实际上也就是环境光的颜色。
```

漫反射和环境反射同时存在时

```
<表面的反射光颜色> = <漫反射光颜色> + <环境反射光颜色>
```

在数学上，对矢量n和l作点积运算，公式是这样的: `n · l= | n | × | 1 | × cosθ`，其中 `||` 符号表示取矢量的长度。可见，如果两个矢量的长度都是1.0，那么其点积的结果就是cosθ值。而内置函数计算点积，实际上是用的下面这个公式: n为 `(nx, ny, nz)`，1为 `(lx, ly, lz)`，那么 `n·l= nx*lx + ny*ly + nz*lz`。 该公式可由余弦定理得到。

则

```
cosθ = <光线方向> · <法线方向>
```

漫反射还能再改一下

```
<漫反射光颜色>=<入射光颜色>x<表面基底色>x(<光线方向> · <法线方向>)
```

这里有两点需要注意：

其一，光线方向矢量和表面法线矢量的长度必须为1，否则反射光的颜色就会过暗或过亮。将一个矢量的长度调整为 1, 同时保持方向不变的过程称之为归一化 (normalization) 。GLSL ES提供了内置的归一化函数，你可以直接使用。

其二，这里 (包括后面) 所谓的“光线方向”，实际上是人射方向的反方向，即从人射点指向光源方向 (因为这样，该方向与法线方向的夹角才是人射角) ，如图8.6所示。

法线：表面的朝向

如果矢量 n 为 (nx, ny, nz)，则其中长度为
$$
|n| = \sqrt{n^2_x + n^2_y + n^2_z}
$$

对矢量n进行归一化后的结果是(nx/m, ny/m, nz/m)，式中m为n的长度。比如，矢量(2.0, 2.0, 1.0)的长度|n|= sqrt(9)=3， 那么其归一化之后就是(2.0/3.0, 2.0/3.0, 1.0/3.0)。向量和矢量为同义词vector，有的书译为“矢量”，但指平面的法线方向时译为“法向量”。

一个表面具有两个法向量

每个表面都有两个面，“正面”和“背面”。两个面各自具有一个法向量。比如，垂直于z轴的x-y平面，其背面的法向量为x正半轴，即(0,0, 1)，如图8.7 (左)所示; 而背面的法向量为x负半轴，即(0,0,-1)， 如图8.7 (右)所示。

在三维图形学中，表面的正面和背面取决于绘制表面时的顶点顺序。当你按照 v0, v1, v2, v3的顶点顺序9绘制了一个平面，那么当你从正面观察这个表面时，这4个顶点是顺时针的，而你从背面观察该表面，这4个顶点就是逆时针的 (即用来确定旋转方向的“右手法则”)。该平面正面的法向量是(0, 0, -1)。

光线方向和法线方向的点积应该是要大于零的，如果是小于零说明角度大于了90度，那就到了表面的背面了，所以计算的点积结果是不能能小于零的

光计算漫反射是不够的，还有环境光反射不要忘了

### 魔法矩阵：逆转置矩阵

计算变换后的法向量要将变换之前的法向量乘以模型矩阵的逆转置矩阵（inverse transpose）即可。所谓逆转置矩阵，就是逆矩阵的转置

逆矩阵的含义是,如果矩阵M的逆矩阵是R,那么R*M或M*R的结果都是单位矩阵。转置的意思是，将矩阵的行列进行调换(看上去就像是沿着左上-右下对角线进行了翻转)。更详细的内容参见附录E‘ 逆转置矩阵”。这里将逆转置矩阵的用法总结如下:

**规则：用法向量乘以模型矩阵的逆转置矩阵，就可以求得变换后的法向量。**

求逆转值矩阵的两个步骤:

1. 求原矩阵的逆矩阵。
2. 将上一步求得的逆矩阵进行转置。

Matrix4对象提供了便捷的方法来完成上述任务

```c
Matrix4 normalMatrix = new Matrix4();
normalMatrix.setInverseOf(modelMatrix); // 使自身(调用本方法的Matrix4类型的实例)成为矩阵m的逆矩阵
normalMatrix.transpose(); // 对自身进行转置操作，并将自身设为转置后的结果
```

[参考例子](http://rodger.global-linguist.com/webgl/ch08/LightedTranslatedRotatedCube.html)

在点光源的情况下，要设置一个光源位置，按照上面的方法照射到立方体表面上会有不自然的线条，这是因为 webgl 系统会根据顶点的颜色，内插出表面上每个片元的颜色。实际上，点光源光照射到一个表面上，所产生的效果(即每个片元获得的颜色)与简单使用4个顶点颜色(虽然这4个顶点的颜色也是由点光源产生)内插出的效果并不完全相同(在某些极端情况下甚至很不一样)，所以为了使效果更加逼真，我们需要对表面的每一点(而不仅仅是4个顶点)计算光照效果。如果使用一个球体，二者的差异可能会更明显。

### 逐片元光照

乍一听，要在表面的每一点上计算光照产生的颜色，似乎是个不可能完成的任务。但实际上，我们只需要逐片元地进行计算。片元着色器总算要派上用场了。

[PointLightedSphere_perFragment](http://rodger.global-linguist.com/webgl/ch08/PointLightedCube_perFragment.html)

为了逐片元地计算光照，需要知道: 

1. 片元在世界坐标系下的坐标
2. 片元处表面的法向量。

可以在顶点着色器中，将顶点的世界坐标和法向量以varying变量的形式传入片元着色器，片元着色器中的同名变量就已经是内插后的逐片元值了。

顶点着色器使用模型矩阵乘以顶点坐标计算出顶点的世界坐标(第16行)，将其赋值给v_ _Position变量。经过内插过程后,片元着色器就获得了逐片元的v_ Position 变量，也就是片元的世界坐标。类似地,顶点着色器将顶点的法向量赋值给v_ Normal 变量12 (第17行)，经过内插，片元着色器就获得了逐片元的v_ Normal变量，即片元的法向量。

片元着色器计算光照效果的方法与 PointlightedCube.js 相同。首先对法向量 v_Normal 进行归一化(第34行)，因为内插之后法向量可能不再是1.0了;然后，计算片元处的光线方向并对其归一-化(第36行);接着计算法向量与光线方向的点积(第38行);最后分别计算点光源光和环境光产生的反射光颜色，并将两个结果加起来，赋值给gl_FragColor，片元就会显示为这个颜色。

如果场景中有超过一个点光源，那么就需要在片元着色器中计算每一个点光源(当然还有环境光)对片元的颜色贡献，并将它们全部加起来。换句话说，有几个点光源，就得按照式计算几次。

## 层次模型

[示例程序](http://rodger.global-linguist.com/webgl/ch09/JointModel.html)

和以前的程序相比，main() 函数基本没有变化(第29行)，主要的变化发生在 initVertexBuffers() 函数中(第47行),它将arm1和arm2的数据写人了相应的缓冲区。以前程序中的立方体都是以原点为中心，且边长为2.0 ;本例为了更好地模拟机器人手臂，使用如图9.6所示的立方体，原点位于底面中心，底面是边长为3.0的正方形，高度为10.0。将原点置于立方体的底面中心，是为了便于使立方体绕关节转动(比如，肘关节就位于前臂立方体的底面中心)，如图9.5所示。arm1 和arm2都使用这个立方体。

... 省略了亿点点细节，看吐了

## 着色器和着色器程序

现在讲讲建立和初始化着色器的一些细节

initShaders 是前面所有示例程序中都用到的一个函数，它不是标准中的东西，是定义的获取着色器和着色器程序对象的工具函数

initShaders() 函数的作用是，编译 GLSL ES 代码，创建和初始化着色器供 WebGL 使用。具体地，分为以下7个步骤:

1. 创建着色器对象(g1. createShader())。
2. 向着色器对象中填充着色器程序的源代码(g1. shaderSource())。
3. 编译着色器(g1. compileShader())。
4. 创建程序对象(g1 .createProgram()。
5. 为程序对象分配着色器(g1. attachShader())。
6. 连接程序对象(g1.linkProgram())。
7. 使用程序对象(gl.useProgram())。 

虽然每一步看上去都比较简单，但是放在一起显得复杂了，我们将逐条讨论。首先，你需要知道这里出现了两种对象：**着色器对象 (shader object) 和程序对象 (program object)**。

着色器对象：着色器对象管理一个顶点着色器或一个片元着色器。每一个着色器都有一个着色器对象。
程序对象：程序对象是管理着色器对象的容器。WebGL中，一个程序对象必须包含一个顶点着色器和一个片元着色器。

下面的 gl 都是 [WebGLRenderingContext](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext) 的实例，mdn 有文档的哈，下面来列举一些比较重要的 api

### 创建着色器对象(gl.createShader(type))

所有的着色器对象都必须通过调用gl.createShader()来创建。

`gl.createShader(type)` 创建由 type 指定的着色器对象

参数 type 指定着色器的类型，`gl.VERTEX_SHADER` 顶点着色器  or `gl.FRAGMENT_SHADER` 片元着色器

返回值是创建的着色器，返回 null 就是创建失败

gl.deleteShader(shader) 就是删除顶点着色器哈

### 指定着色器对象的代码(gl.shaderSource(shader, source))

通过gl. shaderSource()函数向着色器指定GLSL ES源代码。在JavaScript程序中，源代码以字符串的形式存储。

### 编译着色器(gl.compileShader(shader, pname))

向着色器对象传人源代码之后，还需要对其进行编译才能够使用。GLSL ES 语言和 JavaScript 不同而更接近 C 或 C++，在使用之前需要编译成二进制的可执行格式，WebGL系统真正使用的是这种可执行格式。使用 `gl.compileShader()` 函数进行编译。

注意，如果你通过调用 `gl.shaderSource(shader)`，用新的代码替换掉了着色器中旧的代码，WebGL系统中的用旧的代码编译出的可执行部分不会被自动替换，你需要手动地重新进行编译。

当调用 `gl.compileShader(shader)`函数时，如果着色器源代码中存在错误，那么就会出现编译错误。可以调用`gl.getShaderParameter(shader, gl.COMPILE_STATUS)`函数来检查着色器的状态。

`gl.getShaderParameter` 第二个参数接受不同的类型返回不同的值，`gl.SHADER_TYPE` 返回是顶点着色器（gl.VERTEX_SHADER）还是片元着色器（gl.FRAGMENT_SHADER），`gl.DELETE_STATUS` 返回着色器是否被删除成功 ( true 或 false )，`gl.COMPILE_STATUS` 返回着色器是否被编译成功 ( true 或 false )

`gl.getShaderInfoLog(shader)` 获取 shader 指定的着色器的信息日志

虽然日志信息的具体格式依赖于浏览器对 WebGL 的实现，但大多数 WebGL 系统给出的错误信息都会包含代码出错行的行号。

### 创建程序对象(gl.createProgram())

如前所述，程序对象包含了顶点着色器和片元着色器，可以调用 `gl.createProgram()` 来创建程序对象。事实上，之前使用程序对象，`gl.getAttribLocation() ` 函数和 `gl. getUniformLocation()` 函数的第1个参数，就是这个程序对象。

类似地，可以使用 `gl.deleteProgram(program) ` 函数来删除程序对象。

### 为程序对象分配着色器对象(gl.attachShader(program, shader))

WebGL 系统要运行起来，必须要有两个着色器：一个顶点着色器和一个片元着色器。可以使用 `gl .attachShader()` 函数为程序对象分配这两个着色器。

`gl.detachShader(program, shader)` 取消 shader 对 program 指定的程序对象分配

`gl.linkProgram()` 在为程序对象分配了两个着色器对象后，还需要将 ( 顶点着色器和片元 ) 着色器连
接起来。使用 `gl.linkProgram()` 函数来进行这一步操作。 

## 雾化（大气效果）

如何实现雾化

实现雾化的方式有很多种，这里使用最简单的一-种:线性雾化(inear fog)。在线性雾化中，某一点的雾化程度取决于它与视点之间的距离，距离越远雾化程度越高。线性雾化有起点和终点，起点表示开始雾化之处，终点表示完全雾化之处，两点之间某一点的雾化程度与该点与视点的距离呈线性关系。注意，比终点更远的点完全雾化了，即完全看不见了。某一点雾化的程度可以被定义为雾化因子(fog factor)， 并在线性雾化公式中被计算出来

式10.1

$$
<雾化因子> = ( <终点>-<当前点与视点间的距离> ) / ( <终点> - <起点> )
$$

这里

$$
<起点>≤<当前点与视点间的距离>≤<终点>
$$

如果雾化因子为1.0，表示该点完全没有被雾化，可以很清晰地看到此处的物体。如果其为0.0,就表示该点完全雾化了，此处的物体完全看不见。在视线上，起点之前的点的雾化因子为1.0，终点之后的点的雾化因子为0.0。

式10.2
$$
<片元颜色> = <物体表面颜色> × <雾化因子> + <雾的颜色> × ( 1 - <雾化因子> )
$$
内置 clamp 函数， 就是输入一个数让它在一个区间就直接返回，超出区间就返回区间里离它最近的值



















看完了书，在网上冲浪的时候看到了[这个网站](http://www.webglacademy.com/)，感觉十分良心，学习上面的 webgl 基本概念后再用这个网站十分合适




todo: 书中多次提到《计算机图形学》（Computer Graphics）这本书，之前星姐也问我她最感兴趣的是这些东西是怎么渲染的，而不只是使用具体的 api，应该在这本书里有一些答案的

《OpenGL Programming Guide》查看除了线性雾化以外的指数雾化
